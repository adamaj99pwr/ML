{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947a29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist_loader as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cdd7bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def __init__(self, inputSize:int, activ:str):\n",
    "        \n",
    "        self.input = None\n",
    "        self.FPoutput = None\n",
    "        self.BPoutput = None\n",
    "        self.weights = np.random.uniform(low = -1/np.sqrt(inputSize), high = 1/np.sqrt(inputSize), size=(10, inputSize)) # xavier weight initialization\n",
    "        self.activ = activ\n",
    "\n",
    "    #######################################################################\n",
    "    # for first layer, inputData is our data\n",
    "    # for each next layer, inputData is self.FPoutput from PREVIOUS layer   \n",
    "    #######################################################################\n",
    "     \n",
    "    def forwardPass(self, inputData):\n",
    "        \n",
    "        self.input = np.vstack(([1], inputData))\n",
    "        net = self.weights @ self.input\n",
    "        self.FPoutput = self.activation(net) \n",
    "        # print(f'FPoutput: {self.FPoutput.shape}')\n",
    "        \n",
    "    def activation(self, x):\n",
    "\n",
    "        if self.activ == 'sigmoid':\n",
    "            return 1/(1+np.exp(-x))\n",
    "        \n",
    "        elif self.activ == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        \n",
    "        elif self.activ == 'softmax':\n",
    "            exp_x = np.exp(x-np.max(x))  # Subtracting max(x) for numerical stability\n",
    "            return exp_x / np.sum(exp_x)\n",
    "        \n",
    "    def activation_prime(self):\n",
    "\n",
    "        if self.activ == 'sigmoid' or self.activ == 'softmax':\n",
    "            return self.FPoutput * (1 - self.FPoutput)\n",
    "        \n",
    "        elif self.activ == 'tanh':\n",
    "            return 1-self.FPoutput**2\n",
    "\n",
    "        # elif self.activ == 'softmax':\n",
    "        #     return np.diag(self.FPoutput) - np.outer(self.FPoutput, self.FPoutput)\n",
    "        \n",
    "    #######################################################################\n",
    "    # for last layer, the inputData = self.FPoutput - trueLabel\n",
    "    # for each next layer, the inputData = self.BPoutput from PREVIOUS LAYER\n",
    "    #######################################################################\n",
    "    \n",
    "    def backwardPropagation(self, inputData, lr):\n",
    "        \n",
    "        # print(f'input: {inputData.shape}')\n",
    "        # print(f'actprime: {self.activation_prime().shape}')\n",
    "        delta = inputData * self.activation_prime()\n",
    "        dLdW = delta @ self.input.T\n",
    "        new_weights = self.weights - lr * dLdW\n",
    "        dLdX = self.weights.T @ delta\n",
    "        self.weights = new_weights\n",
    "        self.BPoutput = dLdX[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "417f20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.result = None\n",
    "\n",
    "    def fit(self, xTrain, yTrain, epochs, lr):\n",
    "\n",
    "        for _ in range(epochs):\n",
    "\n",
    "            for i in range(len(xTrain)):\n",
    "\n",
    "                output = xTrain[i]\n",
    "                for layer in self.layers:\n",
    "                    layer.forwardPass(output)\n",
    "                    output = layer.FPoutput\n",
    "\n",
    "                error = output - yTrain[i]\n",
    "                for layer in np.flip(self.layers):\n",
    "                    layer.backwardPropagation(error, lr)\n",
    "                    error = layer.BPoutput\n",
    "            \n",
    "            np.random.shuffle(xTrain)\n",
    "    \n",
    "    def predict(self, xTest):\n",
    "\n",
    "        result = [0]*len(xTest)\n",
    "\n",
    "        for i in range(len(xTest)):\n",
    "\n",
    "            output = xTest[i]\n",
    "            for layer in self.layers:\n",
    "                layer.forwardPass(output)\n",
    "                output = layer.FPoutput\n",
    "            \n",
    "            digit = np.argmax(output)\n",
    "            result[i] = digit\n",
    "        \n",
    "        self.result = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "81489e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = ml.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e752dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = zip(*training_data)\n",
    "c, d = zip(*validation_data)\n",
    "a = list(a)\n",
    "b = list(b)\n",
    "c = list(c)\n",
    "d = list(d)\n",
    "trainX = a + c\n",
    "trainY = b + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "509791c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = zip(*test_data)\n",
    "testX = list(testX)\n",
    "testY = list(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fc7137e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = Layer(785, 'sigmoid')\n",
    "L2 = Layer(11, 'tanh')\n",
    "L3 = Layer(11, 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ab72e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNet = Network([L1, L2, L3])\n",
    "NNet.fit(trainX, trainY, 3, 0.1)\n",
    "NNet.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2675ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1137"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = NNet.result\n",
    "accuracy = np.mean(np.array(prediction) == np.array(testY))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74af844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
